{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Actor-Critic网络\"\"\"\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        # 共享特征提取\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(state_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(64)\n",
    "        )\n",
    "        \n",
    "        # 策略头\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, action_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # 价值头\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.shared(x)\n",
    "        return self.policy_head(features), self.value_head(features)\n",
    "\n",
    "\n",
    "class A2CAgent():\n",
    "    \"\"\"调整过的A2C智能体\"\"\"\n",
    "    def __init__(self, env, gamma=0.99, lr=3e-4, n_steps=5, entropy_coef=0.05):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.n_steps = n_steps\n",
    "        self.initial_entropy_coef = entropy_coef\n",
    "        \n",
    "        # 简化的状态表示维度\n",
    "        self.state_dim = 4  # [row, col, rel_col, rel_row]\n",
    "        \n",
    "        # 创建网络\n",
    "        self.model = PolicyNetwork(self.state_dim, len(env.action_space))\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(), \n",
    "            lr=lr, \n",
    "            weight_decay=1e-4  # 添加权重正则化\n",
    "        )\n",
    "        \n",
    "        # 学习率调度器\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, \n",
    "            mode='max',  # 监控奖励\n",
    "            factor=0.5,\n",
    "            patience=50,\n",
    "            min_lr=1e-5,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 训练日志\n",
    "        self.rewards_history = []\n",
    "        self.steps_history = []\n",
    "        self.loss_history = []\n",
    "        self.entropy_coef_history = []\n",
    "    \n",
    "    def state_representation(self, state):\n",
    "        \"\"\"简化的状态表示\"\"\"\n",
    "        row, col = state\n",
    "        goal_row, goal_col = self.env.goal_state\n",
    "        \n",
    "        return torch.tensor([\n",
    "            row / self.env.height,  # 归一化行坐标\n",
    "            col / self.env.width,   # 归一化列坐标\n",
    "            (col - goal_col) / self.env.width,  # 水平相对位置\n",
    "            (row - goal_row) / self.env.height  # 垂直相对位置\n",
    "        ], dtype=torch.float32)\n",
    "    \n",
    "    def compute_returns(self, rewards, next_state, done):\n",
    "        \"\"\"计算折扣回报\"\"\"\n",
    "        next_state_rep = self.state_representation(next_state)\n",
    "        with torch.no_grad():\n",
    "            _, next_value = self.model(next_state_rep.unsqueeze(0))\n",
    "            next_value = next_value.item()\n",
    "        \n",
    "        returns = []\n",
    "        R = next_value if not done else 0\n",
    "        for r in reversed(rewards):\n",
    "            R = r + self.gamma * R\n",
    "            returns.insert(0, R)\n",
    "        return returns\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        \"\"\"根据当前状态选择动作\"\"\"\n",
    "        state_rep = self.state_representation(state)\n",
    "        action_probs, _ = self.model(state_rep.unsqueeze(0))\n",
    "        \n",
    "        # 从概率分布中采样动作\n",
    "        dist = Categorical(action_probs)\n",
    "        action = dist.sample()\n",
    "        \n",
    "        return action.item(), dist.log_prob(action)\n",
    "    \n",
    "    def get_greedy_action(self, state):\n",
    "        \"\"\"获取贪婪策略下的动作（用于评估）\"\"\"\n",
    "        state_rep = self.state_representation(state)\n",
    "        action_probs, _ = self.model(state_rep.unsqueeze(0))\n",
    "        return torch.argmax(action_probs).item()\n",
    "    \n",
    "    def update(self, states, actions, log_probs, rewards, values, masks):\n",
    "        \"\"\"更新网络参数\"\"\"\n",
    "        returns = self.compute_returns(rewards, states[-1], masks[-1])\n",
    "        returns = torch.tensor(returns, dtype=torch.float32)\n",
    "        \n",
    "        # 计算优势函数\n",
    "        values = torch.tensor(values, dtype=torch.float32)\n",
    "        advantages = returns - values\n",
    "        \n",
    "        # 计算损失\n",
    "        actor_loss = -(log_probs * advantages.detach()).mean()\n",
    "        critic_loss = F.mse_loss(values, returns)\n",
    "        \n",
    "        # 计算策略熵\n",
    "        entropy = -(log_probs.exp() * log_probs).mean()\n",
    "        \n",
    "        # 动态熵系数（随训练衰减）\n",
    "        # entropy_coef = max(0.001, self.initial_entropy_coef * (1.0 - len(self.rewards_history)/4000))\n",
    "        \n",
    "        # 改为指数衰减\n",
    "        entropy_coef = max(0.001, self.initial_entropy_coef * 0.9999**len(self.rewards_history))\n",
    "\n",
    "        # 总损失\n",
    "        total_loss = actor_loss + 0.5 * critic_loss - entropy_coef * entropy\n",
    "        \n",
    "        # 梯度更新\n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # 梯度裁剪（防止梯度爆炸）\n",
    "        nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return total_loss.item(), entropy_coef\n",
    "    \n",
    "    def get_policy(self):\n",
    "        \"\"\"获取学习到的策略\"\"\"\n",
    "        greedy_policy = {}  # 状态到最优动作的映射\n",
    "        prob_policy = {}    # 状态到动作概率分布的映射（用于渲染）\n",
    "        \n",
    "        for state in self.env.states():\n",
    "            if state not in self.env.wall_state:  # 跳过墙状态\n",
    "                state_rep = self.state_representation(state)\n",
    "                state_tensor = torch.FloatTensor(state_rep).unsqueeze(0)\n",
    "                action_probs, _ = self.model(state_tensor)\n",
    "                action_probs = action_probs.detach().squeeze().numpy()\n",
    "                \n",
    "                # 找到概率最高的动作\n",
    "                best_action = np.argmax(action_probs)\n",
    "                \n",
    "                # 保存最优动作\n",
    "                greedy_policy[state] = best_action\n",
    "                \n",
    "                # 保存动作概率分布（用于渲染）\n",
    "                probs = {action: float(action_probs[action]) for action in range(len(self.env.action_space))}\n",
    "                prob_policy[state] = probs\n",
    "        \n",
    "        return greedy_policy, prob_policy\n",
    "\n",
    "    def test_policy(self, num_tests=1000, max_steps=300):\n",
    "        \"\"\"测试A2C策略的性能\"\"\"\n",
    "        steps_count = []\n",
    "        success_count = 0\n",
    "        \n",
    "        for i in range(num_tests):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            step_count = 0\n",
    "            \n",
    "            while not done and step_count < max_steps:\n",
    "                # 使用贪婪策略选择动作\n",
    "                action = self.get_greedy_action(state)\n",
    "                \n",
    "                # 执行动作\n",
    "                next_state, reward, done = self.env.step(action)\n",
    "                \n",
    "                # 更新状态\n",
    "                state = next_state\n",
    "                step_count += 1\n",
    "                \n",
    "                # 检查是否成功到达目标\n",
    "                if done and state == self.env.goal_state:\n",
    "                    success_count += 1\n",
    "                    steps_count.append(step_count)\n",
    "                    break\n",
    "                elif done and state != self.env.goal_state:\n",
    "                    # 落入陷阱或撞墙\n",
    "                    break\n",
    "            else:\n",
    "                # 达到最大步数但未完成\n",
    "                pass\n",
    "        \n",
    "        # 计算成功率\n",
    "        success_rate = success_count / num_tests\n",
    "        \n",
    "        # 计算平均步数（仅成功回合）\n",
    "        avg_steps = np.mean(steps_count) if steps_count else 0\n",
    "        \n",
    "        print(f\"\\nA2C Policy Test Results:\")\n",
    "        print(f\"Success Rate: {success_rate:.2%}\")\n",
    "        print(f\"Average Steps (successful episodes): {avg_steps:.2f}\")\n",
    "        print(f\"Total Tests: {num_tests}, Successful: {success_count}\")\n",
    "        \n",
    "        return success_rate, avg_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d1707d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  200, Reward:   0.02, Avg Reward (200):  -0.04, Steps: 300, Loss: 0.0003, Entropy Coef: 0.0475\n",
      "Episode  400, Reward:   0.02, Avg Reward (200):  -0.23, Steps: 300, Loss: -0.0006, Entropy Coef: 0.0450\n",
      "添加惩罚状态(12, 16): -1.0\n",
      "Episode  600, Reward:   0.03, Avg Reward (200):  -0.14, Steps: 300, Loss: -0.0002, Entropy Coef: 0.0425\n",
      "Episode  800, Reward:   2.03, Avg Reward (200):  -0.12, Steps: 287, Loss: 0.1039, Entropy Coef: 0.0400\n",
      "Episode 1000, Reward:   0.01, Avg Reward (200):  -0.23, Steps: 300, Loss: 0.0001, Entropy Coef: 0.0375\n",
      "Episode 1200, Reward:   0.01, Avg Reward (200):  -0.28, Steps: 300, Loss: 0.0009, Entropy Coef: 0.0350\n",
      "Episode 1400, Reward:   0.03, Avg Reward (200):  -0.36, Steps: 300, Loss: 0.0010, Entropy Coef: 0.0325\n",
      "Episode 1600, Reward:   0.02, Avg Reward (200):  -0.28, Steps: 300, Loss: 0.0015, Entropy Coef: 0.0300\n",
      "Episode 1800, Reward:   0.02, Avg Reward (200):  -0.23, Steps: 300, Loss: 0.0016, Entropy Coef: 0.0275\n",
      "Episode 2000, Reward:   0.00, Avg Reward (200):  -0.06, Steps: 300, Loss: 0.0013, Entropy Coef: 0.0250\n",
      "A2C training completed in 855.94 seconds\n",
      "\n",
      "A2C Policy Test Results:\n",
      "Success Rate: 0.00%\n",
      "Average Steps (successful episodes): 0.00\n",
      "Total Tests: 1000, Successful: 0\n",
      "Final Test Success Rate: 0.00%, Avg Steps: 0.00\n",
      "\n",
      "A2C Learned Policy (State -> Best Action):\n",
      "State: (0, 0), Best Action: 0\n",
      "State: (0, 1), Best Action: 0\n",
      "State: (0, 5), Best Action: 0\n",
      "State: (0, 6), Best Action: 0\n",
      "State: (0, 10), Best Action: 0\n",
      "State: (0, 11), Best Action: 0\n",
      "State: (0, 12), Best Action: 0\n",
      "State: (0, 13), Best Action: 0\n",
      "State: (0, 14), Best Action: 0\n",
      "State: (0, 15), Best Action: 0\n",
      "State: (0, 16), Best Action: 0\n",
      "State: (0, 17), Best Action: 0\n",
      "State: (0, 18), Best Action: 0\n",
      "State: (0, 19), Best Action: 0\n",
      "State: (1, 0), Best Action: 0\n",
      "State: (1, 1), Best Action: 0\n",
      "State: (1, 2), Best Action: 0\n",
      "State: (1, 3), Best Action: 0\n",
      "State: (1, 4), Best Action: 0\n",
      "State: (1, 5), Best Action: 0\n",
      "State: (1, 6), Best Action: 0\n",
      "State: (1, 10), Best Action: 0\n",
      "State: (1, 11), Best Action: 0\n",
      "State: (1, 12), Best Action: 0\n",
      "State: (1, 13), Best Action: 0\n",
      "State: (1, 14), Best Action: 0\n",
      "State: (1, 15), Best Action: 0\n",
      "State: (1, 16), Best Action: 0\n",
      "State: (1, 17), Best Action: 0\n",
      "State: (1, 18), Best Action: 0\n",
      "State: (1, 19), Best Action: 0\n",
      "State: (2, 0), Best Action: 0\n",
      "State: (2, 1), Best Action: 0\n",
      "State: (2, 2), Best Action: 0\n",
      "State: (2, 3), Best Action: 0\n",
      "State: (2, 4), Best Action: 0\n",
      "State: (2, 5), Best Action: 0\n",
      "State: (2, 6), Best Action: 0\n",
      "State: (2, 7), Best Action: 0\n",
      "State: (2, 8), Best Action: 0\n",
      "State: (2, 9), Best Action: 0\n",
      "State: (2, 10), Best Action: 0\n",
      "State: (2, 11), Best Action: 0\n",
      "State: (2, 12), Best Action: 0\n",
      "State: (2, 13), Best Action: 0\n",
      "State: (2, 14), Best Action: 0\n",
      "State: (2, 15), Best Action: 0\n",
      "State: (2, 16), Best Action: 0\n",
      "State: (2, 17), Best Action: 0\n",
      "State: (2, 18), Best Action: 0\n",
      "State: (2, 19), Best Action: 0\n",
      "State: (3, 0), Best Action: 0\n",
      "State: (3, 1), Best Action: 0\n",
      "State: (3, 2), Best Action: 0\n",
      "State: (3, 3), Best Action: 0\n",
      "State: (3, 4), Best Action: 0\n",
      "State: (3, 5), Best Action: 0\n",
      "State: (3, 6), Best Action: 0\n",
      "State: (3, 7), Best Action: 0\n",
      "State: (3, 8), Best Action: 0\n",
      "State: (3, 9), Best Action: 0\n",
      "State: (3, 10), Best Action: 0\n",
      "State: (3, 11), Best Action: 0\n",
      "State: (3, 12), Best Action: 0\n",
      "State: (3, 13), Best Action: 0\n",
      "State: (3, 14), Best Action: 0\n",
      "State: (3, 15), Best Action: 0\n",
      "State: (3, 16), Best Action: 0\n",
      "State: (3, 17), Best Action: 0\n",
      "State: (3, 18), Best Action: 0\n",
      "State: (3, 19), Best Action: 0\n",
      "State: (4, 0), Best Action: 0\n",
      "State: (4, 1), Best Action: 0\n",
      "State: (4, 2), Best Action: 0\n",
      "State: (4, 3), Best Action: 0\n",
      "State: (4, 4), Best Action: 0\n",
      "State: (4, 5), Best Action: 0\n",
      "State: (4, 6), Best Action: 0\n",
      "State: (4, 7), Best Action: 0\n",
      "State: (4, 10), Best Action: 0\n",
      "State: (4, 11), Best Action: 0\n",
      "State: (4, 13), Best Action: 0\n",
      "State: (4, 16), Best Action: 0\n",
      "State: (4, 17), Best Action: 0\n",
      "State: (5, 1), Best Action: 0\n",
      "State: (5, 2), Best Action: 0\n",
      "State: (5, 3), Best Action: 0\n",
      "State: (5, 4), Best Action: 0\n",
      "State: (5, 5), Best Action: 0\n",
      "State: (5, 6), Best Action: 0\n",
      "State: (5, 7), Best Action: 0\n",
      "State: (5, 10), Best Action: 0\n",
      "State: (5, 11), Best Action: 0\n",
      "State: (5, 13), Best Action: 0\n",
      "State: (5, 15), Best Action: 0\n",
      "State: (5, 16), Best Action: 0\n",
      "State: (5, 17), Best Action: 0\n",
      "State: (5, 18), Best Action: 0\n",
      "State: (5, 19), Best Action: 0\n",
      "State: (6, 1), Best Action: 0\n",
      "State: (6, 2), Best Action: 0\n",
      "State: (6, 3), Best Action: 0\n",
      "State: (6, 4), Best Action: 0\n",
      "State: (6, 5), Best Action: 0\n",
      "State: (6, 6), Best Action: 0\n",
      "State: (6, 7), Best Action: 0\n",
      "State: (6, 10), Best Action: 0\n",
      "State: (6, 11), Best Action: 0\n",
      "State: (6, 13), Best Action: 0\n",
      "State: (6, 15), Best Action: 0\n",
      "State: (6, 16), Best Action: 0\n",
      "State: (6, 17), Best Action: 0\n",
      "State: (6, 18), Best Action: 0\n",
      "State: (6, 19), Best Action: 0\n",
      "State: (7, 0), Best Action: 0\n",
      "State: (7, 1), Best Action: 0\n",
      "State: (7, 2), Best Action: 0\n",
      "State: (7, 3), Best Action: 0\n",
      "State: (7, 4), Best Action: 0\n",
      "State: (7, 5), Best Action: 0\n",
      "State: (7, 6), Best Action: 0\n",
      "State: (7, 7), Best Action: 0\n",
      "State: (7, 10), Best Action: 0\n",
      "State: (7, 11), Best Action: 0\n",
      "State: (7, 13), Best Action: 0\n",
      "State: (7, 15), Best Action: 0\n",
      "State: (7, 16), Best Action: 0\n",
      "State: (7, 17), Best Action: 0\n",
      "State: (7, 18), Best Action: 0\n",
      "State: (7, 19), Best Action: 0\n",
      "State: (8, 0), Best Action: 0\n",
      "State: (8, 1), Best Action: 0\n",
      "State: (8, 2), Best Action: 0\n",
      "State: (8, 3), Best Action: 0\n",
      "State: (8, 4), Best Action: 0\n",
      "State: (8, 5), Best Action: 0\n",
      "State: (8, 6), Best Action: 0\n",
      "State: (8, 7), Best Action: 0\n",
      "State: (8, 10), Best Action: 0\n",
      "State: (8, 11), Best Action: 0\n",
      "State: (8, 13), Best Action: 0\n",
      "State: (8, 15), Best Action: 0\n",
      "State: (8, 16), Best Action: 0\n",
      "State: (8, 17), Best Action: 0\n",
      "State: (8, 18), Best Action: 0\n",
      "State: (8, 19), Best Action: 0\n",
      "State: (9, 0), Best Action: 0\n",
      "State: (9, 1), Best Action: 0\n",
      "State: (9, 5), Best Action: 0\n",
      "State: (9, 6), Best Action: 0\n",
      "State: (9, 7), Best Action: 0\n",
      "State: (9, 8), Best Action: 0\n",
      "State: (9, 9), Best Action: 0\n",
      "State: (9, 10), Best Action: 0\n",
      "State: (9, 11), Best Action: 0\n",
      "State: (9, 12), Best Action: 0\n",
      "State: (9, 13), Best Action: 0\n",
      "State: (9, 15), Best Action: 0\n",
      "State: (9, 16), Best Action: 0\n",
      "State: (9, 17), Best Action: 0\n",
      "State: (9, 18), Best Action: 0\n",
      "State: (9, 19), Best Action: 0\n",
      "State: (10, 0), Best Action: 0\n",
      "State: (10, 1), Best Action: 0\n",
      "State: (10, 5), Best Action: 0\n",
      "State: (10, 6), Best Action: 0\n",
      "State: (10, 7), Best Action: 0\n",
      "State: (10, 8), Best Action: 0\n",
      "State: (10, 9), Best Action: 0\n",
      "State: (10, 10), Best Action: 0\n",
      "State: (10, 11), Best Action: 0\n",
      "State: (10, 12), Best Action: 0\n",
      "State: (10, 13), Best Action: 0\n",
      "State: (10, 15), Best Action: 0\n",
      "State: (10, 16), Best Action: 0\n",
      "State: (10, 17), Best Action: 0\n",
      "State: (10, 18), Best Action: 0\n",
      "State: (10, 19), Best Action: 0\n",
      "State: (11, 0), Best Action: 0\n",
      "State: (11, 1), Best Action: 0\n",
      "State: (11, 5), Best Action: 0\n",
      "State: (11, 6), Best Action: 0\n",
      "State: (11, 8), Best Action: 0\n",
      "State: (11, 9), Best Action: 0\n",
      "State: (11, 11), Best Action: 0\n",
      "State: (11, 12), Best Action: 0\n",
      "State: (11, 13), Best Action: 0\n",
      "State: (11, 15), Best Action: 0\n",
      "State: (11, 16), Best Action: 0\n",
      "State: (11, 17), Best Action: 0\n",
      "State: (11, 18), Best Action: 0\n",
      "State: (11, 19), Best Action: 0\n",
      "State: (12, 0), Best Action: 0\n",
      "State: (12, 1), Best Action: 0\n",
      "State: (12, 5), Best Action: 0\n",
      "State: (12, 6), Best Action: 0\n",
      "State: (12, 8), Best Action: 0\n",
      "State: (12, 9), Best Action: 0\n",
      "State: (12, 11), Best Action: 0\n",
      "State: (12, 12), Best Action: 0\n",
      "State: (12, 13), Best Action: 0\n",
      "State: (12, 15), Best Action: 0\n",
      "State: (12, 16), Best Action: 0\n",
      "State: (12, 17), Best Action: 0\n",
      "State: (12, 18), Best Action: 0\n",
      "State: (12, 19), Best Action: 0\n",
      "State: (13, 0), Best Action: 0\n",
      "State: (13, 1), Best Action: 0\n",
      "State: (13, 5), Best Action: 0\n",
      "State: (13, 6), Best Action: 0\n",
      "State: (13, 11), Best Action: 0\n",
      "State: (13, 12), Best Action: 0\n",
      "State: (13, 13), Best Action: 0\n",
      "State: (13, 15), Best Action: 0\n",
      "State: (13, 16), Best Action: 0\n",
      "State: (13, 17), Best Action: 0\n",
      "State: (13, 18), Best Action: 0\n",
      "State: (13, 19), Best Action: 0\n",
      "State: (14, 0), Best Action: 0\n",
      "State: (14, 1), Best Action: 0\n",
      "State: (14, 5), Best Action: 0\n",
      "State: (14, 6), Best Action: 0\n",
      "State: (14, 7), Best Action: 0\n",
      "State: (14, 8), Best Action: 0\n",
      "State: (14, 9), Best Action: 0\n",
      "State: (14, 10), Best Action: 0\n",
      "State: (14, 11), Best Action: 0\n",
      "State: (14, 12), Best Action: 0\n",
      "State: (14, 13), Best Action: 0\n",
      "State: (14, 15), Best Action: 0\n",
      "State: (14, 16), Best Action: 0\n",
      "State: (14, 17), Best Action: 0\n",
      "State: (14, 18), Best Action: 0\n",
      "State: (14, 19), Best Action: 0\n",
      "\n",
      "A2C Learned Policy Visualization:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# 确保能够导入环境\n",
    "if \"common_expand\" not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), \"common_expand\"))\n",
    "\n",
    "from common_expand.gridworld import GridWorld\n",
    "\n",
    "# 创建环境\n",
    "env = GridWorld()\n",
    "\n",
    "# 创建智能体\n",
    "agent = A2CAgent(env, gamma=0.99, lr=3e-4, n_steps=5, entropy_coef=0.05)\n",
    "\n",
    "# 主训练函数\n",
    "episodes = 2000\n",
    "log_interval = 200\n",
    "max_steps_per_episode = 300\n",
    "\n",
    "# 保存目录\n",
    "data_root = \"./data_A2C_1\"   \n",
    "# 确保保存目录存在\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "training_data_file = os.path.join(data_root, \"a2c_train_data.csv\")\n",
    "\n",
    "# 初始化训练数据文件\n",
    "with open(training_data_file, \"w\") as f:\n",
    "    f.write(\"episode,total_reward,step_count,loss,entropy_coef\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "    episode_loss = 0\n",
    "    update_count = 0\n",
    "    \n",
    "    # 初始化轨迹数据\n",
    "    states, actions, log_probs, rewards, values, masks = [], [], [], [], [], []\n",
    "    \n",
    "    while not done and step_count < max_steps_per_episode:\n",
    "        # 选择动作\n",
    "        action, log_prob = agent.get_action(state)\n",
    "        \n",
    "        # 执行动作\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        # 改进的奖励塑形：基于距离目标的缩短（系数减小）\n",
    "        goal = env.goal_state\n",
    "        prev_dist = abs(state[0] - goal[0]) + abs(state[1] - goal[1])\n",
    "        next_dist = abs(next_state[0] - goal[0]) + abs(next_state[1] - goal[1])\n",
    "        reward += 0.001 * (prev_dist - next_dist)  # 系数从0.01减小到0.001\n",
    "        \n",
    "        # # 添加陷阱惩罚\n",
    "        # if next_state in env.pit_states:\n",
    "        #     reward -= 0.5\n",
    "        \n",
    "        # 存储转移\n",
    "        state_rep = agent.state_representation(state)\n",
    "        _, state_value = agent.model(state_rep.unsqueeze(0))\n",
    "        state_value = state_value.item()\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        log_probs.append(log_prob)\n",
    "        rewards.append(reward)\n",
    "        values.append(state_value)\n",
    "        masks.append(done)\n",
    "        \n",
    "        # 更新状态\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        step_count += 1\n",
    "        \n",
    "        # N步更新\n",
    "        if len(states) >= agent.n_steps or done:\n",
    "            loss, entropy_coef = agent.update(\n",
    "                states, actions, torch.stack(log_probs), rewards, values, masks\n",
    "            )\n",
    "            \n",
    "            # 记录损失\n",
    "            episode_loss += loss\n",
    "            update_count += 1\n",
    "            \n",
    "            # 记录熵系数\n",
    "            agent.entropy_coef_history.append(entropy_coef)\n",
    "            \n",
    "            # 清空缓冲区\n",
    "            states, actions, log_probs, rewards, values, masks = [], [], [], [], [], []\n",
    "    \n",
    "    # 计算平均损失\n",
    "    avg_loss = episode_loss / update_count if update_count > 0 else 0\n",
    "\n",
    "    if episode == 500:\n",
    "        print(\"添加惩罚状态(12, 16): -1.0\")\n",
    "        env.add_pits((12, 16))\n",
    "        agent.env.add_pits((12, 16))\n",
    "    \n",
    "    # 记录回合数据\n",
    "    agent.rewards_history.append(total_reward)\n",
    "    agent.steps_history.append(step_count)\n",
    "    agent.loss_history.append(avg_loss)\n",
    "    \n",
    "    # 动态调整熵系数\n",
    "    current_entropy_coef = max(0.001, 0.05 * (1.0 - episode / 4000))\n",
    "    \n",
    "    # 更新学习率（基于最近100回合的平均奖励）\n",
    "    if len(agent.rewards_history) > 100:\n",
    "        avg_reward = np.mean(agent.rewards_history[-100:])\n",
    "        agent.scheduler.step(avg_reward)\n",
    "    \n",
    "    # 保存训练数据\n",
    "    with open(training_data_file, \"a\") as f:\n",
    "        f.write(f\"{episode},{total_reward},{step_count},{avg_loss},{current_entropy_coef}\\n\")\n",
    "    \n",
    "    # 打印训练进度\n",
    "    if episode % log_interval == 0:\n",
    "        avg_reward = np.mean(agent.rewards_history[-log_interval:])\n",
    "        print(f\"Episode {episode:4d}, Reward: {total_reward:6.2f}, \"\n",
    "                f\"Avg Reward ({log_interval}): {avg_reward:6.2f}, Steps: {step_count}, \"\n",
    "                f\"Loss: {avg_loss:.4f}, Entropy Coef: {current_entropy_coef:.4f}\")\n",
    "    \n",
    "    # 保存模型\n",
    "    model_path = os.path.join(data_root, \"a2c_gridworld_model_final.pth\")\n",
    "    torch.save({\n",
    "        'model_state_dict': agent.model.state_dict(),\n",
    "        'optimizer_state_dict': agent.optimizer.state_dict(),\n",
    "        'entropy_coef': current_entropy_coef,\n",
    "        'episode': episode\n",
    "    }, model_path)\n",
    "\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"A2C training completed in {duration:.2f} seconds\")\n",
    "\n",
    "# 测试策略\n",
    "success_rate, avg_steps = agent.test_policy(num_tests=1000)\n",
    "print(f\"Final Test Success Rate: {success_rate:.2%}, Avg Steps: {avg_steps:.2f}\")\n",
    "\n",
    "# 可视化策略\n",
    "greedy_policy, prob_policy = agent.get_policy()\n",
    "    \n",
    "print(\"\\nA2C Learned Policy (State -> Best Action):\")\n",
    "for state, best_action in greedy_policy.items():\n",
    "    print(f\"State: {state}, Best Action: {best_action}\")\n",
    "\n",
    "print(\"\\nA2C Learned Policy Visualization:\")\n",
    "env.render_v(None, prob_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55b9bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"可视化训练结果\"\"\"\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "\n",
    "# 奖励曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(agent.rewards_history)\n",
    "plt.title('A2C - Total Reward per Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(data_root, \"a2c_rewards.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 每回合步数\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(agent.steps_history)\n",
    "plt.title('A2C - Steps per Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(data_root, \"a2c_steps.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 损失曲线\n",
    "if agent.loss_history:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(agent.loss_history)\n",
    "    plt.title('A2C - Training Loss per Episode')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(data_root, \"a2c_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 熵系数曲线\n",
    "if agent.entropy_coef_history:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(agent.entropy_coef_history)\n",
    "    plt.title('A2C - Entropy Coefficient per Update')\n",
    "    plt.xlabel('Update')\n",
    "    plt.ylabel('Entropy Coefficient')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(data_root, \"a2c_entropy_coef.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4578a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入模型\n",
    "model = A2C()\n",
    "model.load_state_dict(torch.load('a2c_model.pth'))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
